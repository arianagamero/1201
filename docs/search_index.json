[
["index.html", "Stat1201 Introduction 0.1 Contact 0.2 License", " Stat1201 Joyce Robbins 2018-11-28 Introduction Resources for Stat 1201 If you find online resources that are helpful to this class, please create an issue or send me an email and I’ll add them to this resource. 0.1 Contact Joyce Robbins: Columbia Profile / Website / Twitter / GitHub 0.2 License This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. "],
["ch-1-descriptive-statistics.html", "Ch. 1 Descriptive Statistics 1.2 Stem and leaf plot 0.3 1.2 Frequency histogram 0.4 1.2 Density histogram 0.5 1.3 Measures of location 0.6 1.4 Measures of variability 0.7 1.4 Boxplots", " Ch. 1 Descriptive Statistics 1.2 Stem and leaf plot prices &lt;- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665, 675, 699, 699, 725, 725, 745, 799) stem(prices) ## ## The decimal point is 2 digit(s) to the right of the | ## ## 3 | 8 ## 4 | 355 ## 5 | 03445 ## 6 | 078 ## 7 | 00335 ## 8 | 0 0.3 1.2 Frequency histogram prices &lt;- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665, 675, 699, 699, 725, 725, 745, 799) hist(prices) hist(prices, breaks = c(300, 400, 500, 600, 700, 800), col = &quot;lightblue&quot;) 0.4 1.2 Density histogram prices &lt;- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665, 675, 699, 699, 725, 725, 745, 799) hist(prices, freq = FALSE, breaks = c(300, 400, 500, 600, 700, 800), col = &quot;lightblue&quot;, las = 1) 0.5 1.3 Measures of location prices &lt;- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665, 675, 699, 699, 725, 725, 745, 799) mean(prices) ## [1] 593.2222 median(prices) ## [1] 572 ## quartiles quantile(prices) ## 0% 25% 50% 75% 100% ## 379.0 506.5 572.0 699.0 799.0 ## trimmed mean mean(prices, trim = .1) ## 10% trimmed mean ## [1] 593.75 0.6 1.4 Measures of variability Sample variance prices &lt;- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665, 675, 699, 699, 725, 725, 745, 799) var(prices) ## [1] 15981.48 Sample standard deviation sqrt(var(prices)) ## [1] 126.4179 sd(prices) ## [1] 126.4179 Five number summary (min, lower-hinge, median, upper-hinge, max) fivenum(prices) ## [1] 379 499 572 699 799 0.7 1.4 Boxplots prices &lt;- c(379, 425, 450, 450, 499, 529, 535, 535, 545, 599, 665, 675, 699, 699, 725, 725, 745, 799) boxplot(prices) boxplot(prices, horizontal = TRUE) PTSD &lt;- c(10, 20, 25, 28, 31, 35, 37, 38, 38, 39, 39, 42, 46) Healthy &lt;- c(23, 39, 40, 41, 43, 47, 51, 58, 63, 66, 67, 69, 72) df &lt;- data.frame(Healthy, PTSD) boxplot(df, horizontal = TRUE) "],
["ch-2-probability.html", "Ch. 2 Probability 2.3 Factorial 2.3 Combinations 2.3 Permutations", " Ch. 2 Probability 2.3 Factorial factorial(5) ## [1] 120 2.3 Combinations “5 choose 2” = choose 2 items out of 5 choose(5, 2) ## [1] 10 2.3 Permutations There is no built-in function to calculate permutations. You can multiply the number of combinations by k!. Ex. Number of permutations of size 2 that can be formed from 5 distinct items: choose(5,2)*factorial(2) ## [1] 20 You can create your own function to do this: perm &lt;- function(n, k) {choose(n,k)*factorial(k)} perm(5,2) ## [1] 20 "],
["ch-3-discrete-distributions.html", "Ch. 3 Discrete Distributions 3.3 Expected value 3.3 Variance 3.3 Variance (alternative method) 3.4 Binominal Theorem 3.5 Hypergeometric 3.6 Poisson", " Ch. 3 Discrete Distributions 3.3 Expected value x &lt;- 1:5 x ## [1] 1 2 3 4 5 px &lt;- c(.1, .15, .2, .25, .3) px ## [1] 0.10 0.15 0.20 0.25 0.30 x*px ## [1] 0.1 0.3 0.6 1.0 1.5 sum(x*px) # E(X) ## [1] 3.5 3.3 Variance x - 3.5 ## [1] -2.5 -1.5 -0.5 0.5 1.5 (x - 3.5)^2 ## [1] 6.25 2.25 0.25 0.25 2.25 ((x - 3.5)^2)*px ## [1] 0.6250 0.3375 0.0500 0.0625 0.6750 sum(((x - 3.5)^2)*px) # V(X) ## [1] 1.75 3.3 Variance (alternative method) x ## [1] 1 2 3 4 5 px ## [1] 0.10 0.15 0.20 0.25 0.30 x^2 ## [1] 1 4 9 16 25 (x^2)*px ## [1] 0.1 0.6 1.8 4.0 7.5 sum((x^2)*px) # E(X^2) ## [1] 14 14-3.5^2 # E(X^2) - [E(X)]^2 ## [1] 1.75 3.4 Binominal Theorem choose(8, 3) # &quot;8 choose 3&quot; ## [1] 56 56*.6^3*.4^5 # P(X = 3) given n = 8, p = .6 ## [1] 0.123863 Direct method dbinom(3, 8, .6) # P(X = 3) given n = 8, p = .6 ## [1] 0.123863 3.5 Hypergeometric Note that the notation that R uses is different from the Devore textbook: parameter Devore R total successes M m total failures N-M n sample size n k successes in sample x x Example (p. 127) Devore: h(x; n, M, N) P(X = 2) = h(2; 10, 5, 25) –&gt; dhyper(x = 2, m = 5, n = 20, k = 10) ## [1] 0.3853755 3.6 Poisson Example (p. 132) p(3;2) = dpois(3,2) ## [1] 0.180447 F(3;2) = ppois(3, 2) ## [1] 0.8571235 "],
["ch-4-continuous-random-variables-and-probability-distributions.html", "Ch. 4 Continuous Random Variables and Probability Distributions R", " Ch. 4 Continuous Random Variables and Probability Distributions Sections covered: 4.1, 4.2, 4.3 R \\(P(Z \\leq -1)\\) Unless specified otherwise, pnorm uses a mean of 0 and standard deviation of 1 (standard normal). pnorm(-1) ## [1] 0.1586553 \\(P(X \\leq 37)\\) given \\(\\mu = 40\\) and \\(\\sigma = 2\\) pnorm(37, mean = 40, sd = 2) ## [1] 0.0668072 or pnorm((37-40)/2) ## [1] 0.0668072 \\(P(X &gt; 39)\\) 1 - pnorm(39, mean = 40, sd = 2) ## [1] 0.6914625 Find the 75th percentile for the standard normal distribution: qnorm(.75) ## [1] 0.6744898 Find the 75th percentile for a normally distribution population with mean 40 and standard deviation 2: qnorm(.75, mean = 40, sd = 2) ## [1] 41.34898 or 40 + qnorm(.75)*2 ## [1] 41.34898 "],
["ch-5-random-samples.html", "Ch. 5 Random Samples 5.4 The Distribution of the Sample Mean 5.5 The Distribution of a Linear Combination", " Ch. 5 Random Samples Sections covered: 5.3, 5.4, 5.5 5.4 The Distribution of the Sample Mean Central Limit Theorem visualization: http://mfviz.com/central-limit/ 5.5 The Distribution of a Linear Combination Skip (for now): formula (5.11) – variance of a linear combination not assuming independence of \\(X_i\\)’s. "],
["ch-6-point-estimation.html", "Ch. 6 Point Estimation 6.1 Some General Concepts of Point Estimation", " Ch. 6 Point Estimation Sections covered: 6.1 6.1 Some General Concepts of Point Estimation Skip everything beginning with “Some Complications” on p. 257 "],
["ch-7-statistical-intervals-based-on-a-single-sample.html", "Ch. 7 Statistical Intervals Based on a Single Sample 7.1 Basic Properties of Confidence Intervals 7.2 Large-Sample Confidence Intervals for a Population Mean and Proportion 7.3 Intervals Based on a Normal Population Distribution", " Ch. 7 Statistical Intervals Based on a Single Sample Sections covered: 7.1, 7.2, 7.3 7.1 Basic Properties of Confidence Intervals Skip: “Deriving a Confidence Interval”, pp. 282-284; “Bootstrap Confidence Intervals”, p. 284 7.2 Large-Sample Confidence Intervals for a Population Mean and Proportion You may use: \\(\\hat{p} \\pm z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}\\hat{q}}{n}}\\), rather than the formula (7.10) in the blue box on p. 289 for large sample confidence intervals for proportions, skip p. 290 You may use the method from class \\(n = \\frac{4z^2\\hat{p}\\hat{q}}{w^2}\\) for the minimum \\(n\\) needed to ensure a particular confidence interval width for proportions, rather than formula (7.12) – both appear on p. 291. As noted in Example 7.9 on p. 291, the easier formula gives a slightly different answer (385 instead of 381). 7.3 Intervals Based on a Normal Population Distribution Skip “A Prediction Interval for a Single Future Value” p. 299 to the end of the section "],
["ch-8-tests-of-hypotheses-based-on-a-single-sample.html", "Ch. 8 Tests of Hypotheses Based on a Single Sample 8.1 Hypotheses and Test Procedures 8.2 z Tests for Hypotheses about a Population Mean 8.3 The One-Sample t Test 8.4 Tests Concerning a Population Proportion", " Ch. 8 Tests of Hypotheses Based on a Single Sample Sections covered: 8.1, 8.2, 8.3, 8.4 8.1 Hypotheses and Test Procedures Skip: Example 8.4 (hypothesis testing and type II error calculation for small sample proportions) xkcd cartoon: “Significant” (Jelly Beans Cause Acne!) 8.2 z Tests for Hypotheses about a Population Mean Skip: calculating Type II error and sample size needed for two sided tests (3rd and 5th formulas in the blue box on p. 331) 8.3 The One-Sample t Test Skip: \\(\\beta\\) and Sample Size Determination (p. 338) to end of section 8.4 Tests Concerning a Population Proportion Skip: \\(\\beta\\) and Sample Size Determination (pp. 348-349) "],
["ch-9-inferences-based-on-two-samples.html", "Ch. 9 Inferences Based on Two Samples 9.1 \\(z\\) Tests and CI’s for a Difference Between Two Population Means 9.2 The Two-Sample \\(t\\) Test and CI 9.3 Analysis of Paired Data 9.4 Inferences Concerning a Difference Between Population Proportions", " Ch. 9 Inferences Based on Two Samples Sections covered: 9.1, 9.2, 9.3, 9.4 9.1 \\(z\\) Tests and CI’s for a Difference Between Two Population Means (Cases 1 &amp; 2) Skip: \\(\\beta\\) and the Choice of Sample Size (pp. 366-367) R Since you aren’t given the original data, R isn’t very helpful here, but you can write a function that you could reuse, such as: options(scipen = 999) # get rid of scientific notation # this function only has to be run once per session, and then you can reuse it. diffmeans &lt;- function(xbar, ybar, delta0, sigma1, sigma2, m, n, type = &quot;twosided&quot;) { Z &lt;- ((xbar - ybar) - delta0)/sqrt(((sigma1^2)/m) + ((sigma2^2)/n)) if (type == &quot;twosided&quot;) { pvalue &lt;- pnorm(-abs(Z))*2 } else if (type == &quot;lowertail&quot;) { pvalue &lt;- pnorm(Z) } else { pvalue &lt;- 1 - pnorm(Z) } print(c(&quot;The p-value is&quot;, round(pvalue, 4))) } # Example 9.1, p. 365 diffmeans(xbar = 29.8, ybar = 34.7, delta0 = 0, sigma1 = 4, sigma2 = 5, m = 20, n = 25, type = &quot;twosided&quot;) ## [1] &quot;The p-value is&quot; &quot;0.0003&quot; # Example 9.4, p. 368 # As long as you use the correct order of parameters, you don&#39;t have to write out the names: diffmeans(2258, 2637, -200, 1519, 1138, 663, 413, &quot;lowertail&quot;) ## [1] &quot;The p-value is&quot; &quot;0.0139&quot; 9.2 The Two-Sample \\(t\\) Test and CI (Case 3) Use: http://bit.ly/degreesoffreedom to calculate the degrees of freedom Skip: Pooled \\(t\\) Procedures (pp. 377-378) Skip: Type II Error Probabilities (pp. 378-379) 9.3 Analysis of Paired Data Skip: Paired Data and Two-Sample \\(t\\) Procedures (pp. 386-387) Skip: Paired Versus Unpaired Experiments (pp. 387-388) 9.4 Inferences Concerning a Difference Between Population Proportions Skip: Type II Error Probabilities and Sample Sizes (pp. 394-395) R A/B Testing question from class: clicks &lt;- c(25, 20) people &lt;- c(100, 100) prop.test(clicks, people, correct = FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: clicks out of people ## X-squared = 0.71685, df = 1, p-value = 0.3972 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.06553817 0.16553817 ## sample estimates: ## prop 1 prop 2 ## 0.25 0.20 "],
["ch-2-conditional-probability.html", "Ch. 2 Conditional Probability Resources", " Ch. 2 Conditional Probability Section covered: 2.4 Resources An Intuitive (and Short) Explanation of Bayes’ Theorem "],
["ch-5-joint-probability.html", "Ch. 5 Joint Probability 5.1 Jointly Distributed Random Variables 5.2 Expected Values, Covariance, and Correlation", " Ch. 5 Joint Probability Sections covered: 5.1, 5.2 5.1 Jointly Distributed Random Variables Skip: “Two Continuous Random Variables” (pp. 201-204); Examples 5.7, 5.8 p. 205; “More Than Two Random Variables” pp. 205-208; “Conditional Distributions” p. 209 5.2 Expected Values, Covariance, and Correlation Skip: all double integrals, “The Bivariate Normal Distribution” pp. 218-219 "],
["ch-14-chi-squared-test.html", "Ch. 14 Chi Squared Test 14.3 Two-Way Contingency Tables Resources R", " Ch. 14 Chi Squared Test Sections covered: 14.3 14.3 Two-Way Contingency Tables Skip: pp. 639-643, focus on “Testing for Independence (Lack of Association)” (“estimated expected” in the textbook is the same as “expected” used in class) Resources Chi Square Table Chi Squared Test Calculator Chi Squared Distribution Curves R The chisq.test() function requires that data be in matrix form: # p. 647, #28 mat &lt;- matrix(c(28, 17, 7, 31, 26, 10, 26, 19, 11), nrow = 3, byrow = TRUE) dimnames(mat) &lt;- list(`Email_Provider` = c(&quot;gmail&quot;, &quot;Yahoo&quot;, &quot;Other&quot;), `Cell_Phone_Provider` = c(&quot;ATT&quot;, &quot;Verizon&quot;, &quot;Other&quot;)) chisq.test(mat, correct = FALSE) ## ## Pearson&#39;s Chi-squared test ## ## data: mat ## X-squared = 1.5074, df = 4, p-value = 0.8253 To see the expected values: results &lt;- chisq.test(mat, correct = FALSE) round(results$expected, 2) ## Cell_Phone_Provider ## Email_Provider ATT Verizon Other ## gmail 25.26 18.42 8.32 ## Yahoo 32.54 23.74 10.72 ## Other 27.20 19.84 8.96 Mosaic plot mosaicplot(t(mat), color = c(&quot;aliceblue&quot;, &quot;cornflowerblue&quot;, &quot;navyblue&quot;), main = &quot;&quot;) See this tutorial for more on mosaic plots. "]
]
